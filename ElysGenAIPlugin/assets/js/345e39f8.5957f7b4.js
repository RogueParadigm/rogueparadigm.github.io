"use strict";(globalThis.webpackChunkelysgenai_docs=globalThis.webpackChunkelysgenai_docs||[]).push([[314],{5121(e,n,r){r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>u,default:()=>c,frontMatter:()=>o,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"AudioCapture","title":"Audio Capture System","description":"Understanding ElysGenAI\'s audio capture, routing, and consumer pattern.","source":"@site/../Documentation/AudioCapture.md","sourceDirName":".","slug":"/AudioCapture","permalink":"/ElysGenAIPlugin/AudioCapture","draft":false,"unlisted":false,"editUrl":"https://github.com/RogueParadigm/ElysGenAIPlugin/tree/main/Documentation/../Documentation/AudioCapture.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"id":"AudioCapture","title":"Audio Capture System","sidebar_position":7},"sidebar":"docsSidebar","previous":{"title":"Multiplayer Guide","permalink":"/ElysGenAIPlugin/MultiplayerGuide"},"next":{"title":"Speech-to-Text Guide","permalink":"/ElysGenAIPlugin/STTGuide"}}');var s=r(4848),t=r(8453);const o={id:"AudioCapture",title:"Audio Capture System",sidebar_position:7},u="Audio Capture System",l={},a=[{value:"Overview",id:"overview",level:2},{value:"Audio Capture Subsystem",id:"audio-capture-subsystem",level:2},{value:"Access",id:"access",level:3},{value:"Lifecycle",id:"lifecycle",level:3},{value:"Consumer Pattern",id:"consumer-pattern",level:2},{value:"Implementing a Consumer",id:"implementing-a-consumer",level:3},{value:"Registering",id:"registering",level:3},{value:"Push-to-Talk Modes",id:"push-to-talk-modes",level:2},{value:"Modes",id:"modes",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Input Binding",id:"input-binding",level:3},{value:"Mute/Unmute",id:"muteunmute",level:2},{value:"Audio Format",id:"audio-format",level:2},{value:"Audio Buffer",id:"audio-buffer",level:2},{value:"Ring Buffer",id:"ring-buffer",level:2},{value:"Examples",id:"examples",level:2},{value:"Voice Recording",id:"voice-recording",level:3},{value:"Audio Visualizer",id:"audio-visualizer",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"No Audio Captured",id:"no-audio-captured",level:3},{value:"Low Quality Audio",id:"low-quality-audio",level:3},{value:"Clicks/Pops in Audio",id:"clickspops-in-audio",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"audio-capture-system",children:"Audio Capture System"})}),"\n",(0,s.jsx)(n.p,{children:"Understanding ElysGenAI's audio capture, routing, and consumer pattern."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"UERP_AudioCaptureSubsystem"})," captures microphone input and distributes it to multiple consumers (STT, voice chat, recording)."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Key Features:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Single capture point"}),"\n",(0,s.jsx)(n.li,{children:"Fan-out to multiple consumers"}),"\n",(0,s.jsx)(n.li,{children:"Push-to-talk modes"}),"\n",(0,s.jsx)(n.li,{children:"Mute/unmute support"}),"\n",(0,s.jsx)(n.li,{children:"Ring buffer for audio history"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"audio-capture-subsystem",children:"Audio Capture Subsystem"}),"\n",(0,s.jsx)(n.h3,{id:"access",children:"Access"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"UERP_AudioCaptureSubsystem* AudioSubsystem = \r\n    GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n"})}),"\n",(0,s.jsx)(n.h3,{id:"lifecycle",children:"Lifecycle"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// Automatic initialization\r\nvoid UERP_AudioCaptureSubsystem::Initialize(FSubsystemCollectionBase& Collection)\r\n{\r\n    // Setup audio capture\r\n    // Initialize ring buffer\r\n    // Register with engine audio system\r\n}\r\n\r\n// Automatic cleanup\r\nvoid UERP_AudioCaptureSubsystem::Deinitialize()\r\n{\r\n    StopCapture();\r\n    // Release audio resources\r\n}\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"consumer-pattern",children:"Consumer Pattern"}),"\n",(0,s.jsx)(n.h3,{id:"implementing-a-consumer",children:"Implementing a Consumer"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'// YourComponent.h\r\nUCLASS()\r\nclass UMyAudioConsumerERP : public UActorComponent, public IERP_AudioConsumer\r\n{\r\n    GENERATED_BODY()\r\n    \r\npublic:\r\n    // IERP_AudioConsumer interface\r\n    virtual void OnAudioDataReceived_Implementation(const FElysAudioBuffer& Buffer) override\r\n    {\r\n        // Process audio\r\n        ProcessAudio(Buffer.AudioData);\r\n    }\r\n    \r\n    virtual FString GetConsumerName_Implementation() const override\r\n    {\r\n        return TEXT("MyAudioConsumer");\r\n    }\r\n};\n'})}),"\n",(0,s.jsx)(n.h3,{id:"registering",children:"Registering"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"void UMyAudioConsumerERP::BeginPlay()\r\n{\r\n    Super::BeginPlay();\r\n    \r\n    UERP_AudioCaptureSubsystem* AudioSubsystem = \r\n        GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\r\n    \r\n    if (AudioSubsystem)\r\n    {\r\n        AudioSubsystem->RegisterConsumer(this);\r\n    }\r\n}\r\n\r\nvoid UMyAudioConsumerERP::EndPlay(const EEndPlayReason::Type Reason)\r\n{\r\n    if (UERP_AudioCaptureSubsystem* AudioSubsystem = \r\n        GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>())\r\n    {\r\n        AudioSubsystem->UnregisterConsumer(this);\r\n    }\r\n    \r\n    Super::EndPlay(Reason);\r\n}\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"push-to-talk-modes",children:"Push-to-Talk Modes"}),"\n",(0,s.jsx)(n.h3,{id:"modes",children:"Modes"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"UENUM(BlueprintType)\r\nenum class EElysPushToTalkMode : uint8\r\n{\r\n    AlwaysOn,      // Continuous capture\r\n    PushToTalk,    // Hold key to talk\r\n    PushToMute     // Hold key to mute\r\n};\n"})}),"\n",(0,s.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Blueprint:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Project Settings \u2192 Elys GenAI Framework \u2192 Audio\r\n- PTT Mode: Push To Talk\r\n- PTT Key: Left Shift\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"C++:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"AudioSubsystem->SetPushToTalkMode(EElysPushToTalkMode::PushToTalk);\r\nAudioSubsystem->SetPushToTalkActive(true); // Key pressed\r\nAudioSubsystem->SetPushToTalkActive(false); // Key released\n"})}),"\n",(0,s.jsx)(n.h3,{id:"input-binding",children:"Input Binding"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'// In PlayerController\r\nvoid AMyPlayerController::SetupInputComponent()\r\n{\r\n    Super::SetupInputComponent();\r\n    \r\n    InputComponent->BindAction("VoiceChat", IE_Pressed, this, &AMyPlayerController::StartVoiceChat);\r\n    InputComponent->BindAction("VoiceChat", IE_Released, this, &AMyPlayerController::StopVoiceChat);\r\n}\r\n\r\nvoid AMyPlayerController::StartVoiceChat()\r\n{\r\n    if (UERP_AudioCaptureSubsystem* AudioSubsystem = \r\n        GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>())\r\n    {\r\n        AudioSubsystem->SetPushToTalkActive(true);\r\n    }\r\n}\r\n\r\nvoid AMyPlayerController::StopVoiceChat()\r\n{\r\n    if (UERP_AudioCaptureSubsystem* AudioSubsystem = \r\n        GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>())\r\n    {\r\n        AudioSubsystem->SetPushToTalkActive(false);\r\n    }\r\n}\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"muteunmute",children:"Mute/Unmute"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// Mute microphone\r\nAudioSubsystem->SetMuted(true);\r\n\r\n// Unmute microphone\r\nAudioSubsystem->SetMuted(false);\r\n\r\n// Check mute state\r\nbool bIsMuted = AudioSubsystem->IsMuted();\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"audio-format",children:"Audio Format"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\r\nstruct FElysAudioFormat\r\n{\r\n    UPROPERTY(BlueprintReadWrite)\r\n    int32 SampleRate = 16000;  // Hz\r\n    \r\n    UPROPERTY(BlueprintReadWrite)\r\n    int32 NumChannels = 1;  // Mono\r\n    \r\n    UPROPERTY(BlueprintReadWrite)\r\n    int32 BitsPerSample = 16;\r\n};\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Common Formats:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"16kHz, Mono, 16-bit"})," - Whisper STT (recommended)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"48kHz, Stereo, 16-bit"})," - Voice chat"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"44.1kHz, Stereo, 16-bit"})," - Recording"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"audio-buffer",children:"Audio Buffer"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\r\nstruct FElysAudioBuffer\r\n{\r\n    UPROPERTY(BlueprintReadOnly)\r\n    TArray<float> AudioData;  // [-1.0, 1.0]\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    FElysAudioFormat Format;\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    FDateTime Timestamp;\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    int32 SequenceNumber;\r\n};\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"ring-buffer",children:"Ring Buffer"}),"\n",(0,s.jsx)(n.p,{children:"Internal circular buffer for audio history:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"class FERP_AudioRingBuffer\r\n{\r\npublic:\r\n    void Initialize(int32 Capacity, const FElysAudioFormat& Format);\r\n    void Write(const TArray<float>& AudioData);\r\n    TArray<float> Read(int32 NumSamples);\r\n    void Clear();\r\n    \r\n    int32 GetCapacity() const;\r\n    int32 GetAvailable() const;\r\n};\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,s.jsx)(n.h3,{id:"voice-recording",children:"Voice Recording"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"UCLASS()\r\nclass UVoiceRecorderERP : public UActorComponent, public IERP_AudioConsumer\r\n{\r\n    GENERATED_BODY()\r\n    \r\npublic:\r\n    UFUNCTION(BlueprintCallable)\r\n    void StartRecording();\r\n    \r\n    UFUNCTION(BlueprintCallable)\r\n    void StopRecording();\r\n    \r\n    UFUNCTION(BlueprintCallable)\r\n    void SaveToFile(const FString& Filename);\r\n    \r\n    virtual void OnAudioDataReceived_Implementation(const FElysAudioBuffer& Buffer) override\r\n    {\r\n        if (bIsRecording)\r\n        {\r\n            RecordedAudio.Append(Buffer.AudioData);\r\n        }\r\n    }\r\n    \r\nprivate:\r\n    bool bIsRecording = false;\r\n    TArray<float> RecordedAudio;\r\n};\n"})}),"\n",(0,s.jsx)(n.h3,{id:"audio-visualizer",children:"Audio Visualizer"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"UCLASS()\r\nclass UAudioVisualizerERP : public UActorComponent, public IERP_AudioConsumer\r\n{\r\n    GENERATED_BODY()\r\n    \r\npublic:\r\n    virtual void OnAudioDataReceived_Implementation(const FElysAudioBuffer& Buffer) override\r\n    {\r\n        // Calculate RMS for volume bars\r\n        float RMS = CalculateRMS(Buffer.AudioData);\r\n        CurrentVolume = RMS;\r\n        \r\n        // Update frequency spectrum\r\n        FFT(Buffer.AudioData, FrequencyBins);\r\n        \r\n        OnVisualizationUpdate.Broadcast(CurrentVolume, FrequencyBins);\r\n    }\r\n    \r\n    UPROPERTY(BlueprintAssignable)\r\n    FOnVisualizationUpdate OnVisualizationUpdate;\r\n    \r\nprivate:\r\n    float CurrentVolume;\r\n    TArray<float> FrequencyBins;\r\n    \r\n    float CalculateRMS(const TArray<float>& Audio);\r\n    void FFT(const TArray<float>& Audio, TArray<float>& OutBins);\r\n};\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.h3,{id:"no-audio-captured",children:"No Audio Captured"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Check:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Microphone permissions (OS settings)"}),"\n",(0,s.jsx)(n.li,{children:"Default audio device in Windows/Mac settings"}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"IsCapturing()"})," returns true"]}),"\n",(0,s.jsx)(n.li,{children:"Consumer registered with subsystem"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"low-quality-audio",children:"Low Quality Audio"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Solutions:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Increase sample rate (16kHz \u2192 48kHz)"}),"\n",(0,s.jsx)(n.li,{children:"Reduce background noise"}),"\n",(0,s.jsx)(n.li,{children:"Use better microphone"}),"\n",(0,s.jsx)(n.li,{children:"Enable noise suppression (future feature)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"clickspops-in-audio",children:"Clicks/Pops in Audio"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cause:"})," Buffer underrun"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Solution:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// Increase buffer duration\r\nAudioSubsystem->SetBufferDuration(200); // ms (default: 100ms)\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ElysGenAIPlugin/STTGuide",children:"STT Guide"})})," - Use audio for speech-to-text"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ElysGenAIPlugin/Examples",children:"Examples"})})," - More audio consumer examples"]}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,r){r.d(n,{R:()=>o,x:()=>u});var i=r(6540);const s={},t=i.createContext(s);function o(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function u(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);