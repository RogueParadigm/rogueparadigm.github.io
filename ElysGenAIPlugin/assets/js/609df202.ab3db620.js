"use strict";(globalThis.webpackChunkelysgenai_docs=globalThis.webpackChunkelysgenai_docs||[]).push([[208],{3648(e,n,t){t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>u,frontMatter:()=>l,metadata:()=>s,toc:()=>a});const s=JSON.parse('{"id":"ModulesGuide","title":"Modules Guide","description":"Complete guide to Audio Capture, Speech-to-Text, and Language Models.","source":"@site/../Documentation/ModulesGuide.md","sourceDirName":".","slug":"/ModulesGuide","permalink":"/ElysGenAIPlugin/ModulesGuide","draft":false,"unlisted":false,"editUrl":"https://github.com/RogueParadigm/ElysGenAIPlugin/tree/main/Documentation/../Documentation/ModulesGuide.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ModulesGuide","title":"Modules Guide","sidebar_position":4},"sidebar":"docsSidebar","previous":{"title":"Core Concepts","permalink":"/ElysGenAIPlugin/CoreConcepts"},"next":{"title":"Examples","permalink":"/ElysGenAIPlugin/Examples"}}');var i=t(4848),r=t(8453);const l={id:"ModulesGuide",title:"Modules Guide",sidebar_position:4},d="Modules Guide",o={},a=[{value:"Overview",id:"overview",level:2},{value:"Audio Capture System",id:"audio-capture-system",level:2},{value:"Quick Start",id:"quick-start",level:3},{value:"Consumer Pattern",id:"consumer-pattern",level:3},{value:"Register Consumer",id:"register-consumer",level:3},{value:"Push-to-Talk Modes",id:"push-to-talk-modes",level:3},{value:"Audio Formats",id:"audio-formats",level:3},{value:"Mute Control",id:"mute-control",level:3},{value:"Speech-to-Text (STT)",id:"speech-to-text-stt",level:2},{value:"Quick Setup",id:"quick-setup",level:3},{value:"Component API",id:"component-api",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Events",id:"events",level:3},{value:"Whisper Models",id:"whisper-models",level:3},{value:"Voice Activity Detection (VAD)",id:"voice-activity-detection-vad",level:3},{value:"Performance Tuning",id:"performance-tuning",level:3},{value:"Language Models (LLM)",id:"language-models-llm",level:2},{value:"Quick Setup",id:"quick-setup-1",level:3},{value:"Component API",id:"component-api-1",level:3},{value:"Configuration",id:"configuration-1",level:3},{value:"Events",id:"events-1",level:3},{value:"Bundled Model: Phi-3-mini",id:"bundled-model-phi-3-mini",level:3},{value:"Temperature Guide",id:"temperature-guide",level:3},{value:"System Prompt Best Practices",id:"system-prompt-best-practices",level:3},{value:"Combined Examples",id:"combined-examples",level:2},{value:"Voice-to-Dialogue Pipeline",id:"voice-to-dialogue-pipeline",level:3},{value:"Multi-Consumer Audio Routing",id:"multi-consumer-audio-routing",level:3},{value:"Settings Reference",id:"settings-reference",level:2},{value:"Audio Settings",id:"audio-settings",level:3},{value:"STT Settings",id:"stt-settings",level:3},{value:"LLM Settings",id:"llm-settings",level:3},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"modules-guide",children:"Modules Guide"})}),"\n",(0,i.jsx)(n.p,{children:"Complete guide to Audio Capture, Speech-to-Text, and Language Models."}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"ElysGenAI provides three integrated modules:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Microphone \u2192 Audio Capture \u2192 STT \u2192 Transcribed Text \u2192 LLM \u2192 Generated Response\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Modules:"})}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Audio Capture"})," - Microphone input and routing"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"STT"})," - Speech-to-text using Whisper"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"LLM"})," - Language models using Phi-3-mini"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"audio-capture-system",children:"Audio Capture System"}),"\n",(0,i.jsx)(n.h3,{id:"quick-start",children:"Quick Start"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// Get subsystem\nUERP_AudioCaptureSubsystem* AudioSubsystem = \n    GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n\n// Start capturing\nAudioSubsystem->StartCapture();\n"})}),"\n",(0,i.jsx)(n.h3,{id:"consumer-pattern",children:"Consumer Pattern"}),"\n",(0,i.jsxs)(n.p,{children:["Implement ",(0,i.jsx)(n.code,{children:"IERP_AudioConsumer"})," to receive audio:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UCLASS()\nclass UMyAudioConsumer : public UObject, public IERP_AudioConsumer\n{\n    GENERATED_BODY()\n    \npublic:\n    virtual void OnAudioDataReceived_Implementation(const FERP_AudioBuffer& Buffer) override\n    {\n        // Process audio\n        ProcessAudio(Buffer.AudioData);\n    }\n    \n    virtual FString GetConsumerName_Implementation() const override\n    {\n        return TEXT("MyAudioConsumer");\n    }\n};\n'})}),"\n",(0,i.jsx)(n.h3,{id:"register-consumer",children:"Register Consumer"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"void UMyComponent::BeginPlay()\n{\n    Super::BeginPlay();\n    \n    UERP_AudioCaptureSubsystem* AudioSubsystem = \n        GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n    \n    if (AudioSubsystem)\n    {\n        AudioSubsystem->RegisterConsumer(this);\n    }\n}\n\nvoid UMyComponent::EndPlay(const EEndPlayReason::Type Reason)\n{\n    if (UERP_AudioCaptureSubsystem* AudioSubsystem = \n        GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>())\n    {\n        AudioSubsystem->UnregisterConsumer(this);\n    }\n    \n    Super::EndPlay(Reason);\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"push-to-talk-modes",children:"Push-to-Talk Modes"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"UENUM(BlueprintType)\nenum class EElysPushToTalkMode : uint8\n{\n    AlwaysOn,      // Continuous capture\n    PushToTalk,    // Hold key to talk\n    PushToMute     // Hold key to mute\n};\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Configuration:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"AudioSubsystem->SetPushToTalkMode(EElysPushToTalkMode::PushToTalk);\nAudioSubsystem->SetPushToTalkActive(true); // Key pressed\nAudioSubsystem->SetPushToTalkActive(false); // Key released\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Input Binding:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'// In PlayerController\nvoid AMyPlayerController::SetupInputComponent()\n{\n    Super::SetupInputComponent();\n    \n    InputComponent->BindAction("VoiceChat", IE_Pressed, this, &AMyPlayerController::StartVoiceChat);\n    InputComponent->BindAction("VoiceChat", IE_Released, this, &AMyPlayerController::StopVoiceChat);\n}\n\nvoid AMyPlayerController::StartVoiceChat()\n{\n    auto* AudioSubsystem = GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n    AudioSubsystem->SetPushToTalkActive(true);\n}\n\nvoid AMyPlayerController::StopVoiceChat()\n{\n    auto* AudioSubsystem = GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n    AudioSubsystem->SetPushToTalkActive(false);\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"audio-formats",children:"Audio Formats"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\nstruct FERP_AudioFormat\n{\n    int32 SampleRate;   // 16000 (STT), 48000 (voice chat)\n    int32 NumChannels;  // 1 (mono), 2 (stereo)\n    int32 BitDepth;     // 16\n};\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"STT Default:"})," 16kHz mono 16-bit\n",(0,i.jsx)(n.strong,{children:"Voice Chat Default:"})," 48kHz stereo 16-bit"]}),"\n",(0,i.jsx)(n.h3,{id:"mute-control",children:"Mute Control"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// Mute microphone\nAudioSubsystem->SetMuted(true);\n\n// Check mute status\nbool bIsMuted = AudioSubsystem->IsMuted();\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"speech-to-text-stt",children:"Speech-to-Text (STT)"}),"\n",(0,i.jsx)(n.h3,{id:"quick-setup",children:"Quick Setup"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'// 1. Add component to Actor\nUPROPERTY(VisibleAnywhere, BlueprintReadOnly)\nUERP_STTComponent* STTComponent;\n\n// 2. Bind event\nSTTComponent->OnTranscriptionComplete.AddDynamic(\n    this, &AMyActor::OnTranscriptionReceived);\n\n// 3. Start listening\nSTTComponent->StartListening();\n\n// 4. Handle results\nvoid AMyActor::OnTranscriptionReceived(const FERP_STTResult& Result)\n{\n    UE_LOG(LogTemp, Log, TEXT("Transcription: %s"), *Result.TranscribedText);\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"component-api",children:"Component API"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"StartListening:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|STT")\nvoid StartListening();\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"StopListening:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|STT")\nvoid StopListening();\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"IsListening:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintPure, Category="ElysGenAI|STT")\nbool IsListening() const;\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"SetLanguageCode:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|STT")\nvoid SetLanguageCode(const FString& LanguageCode);\n'})}),"\n",(0,i.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Component Properties:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UPROPERTY(EditAnywhere, BlueprintReadWrite, Category="ElysGenAI|STT")\nbool bAutoStartListening = false;\n\nUPROPERTY(EditAnywhere, BlueprintReadWrite, Category="ElysGenAI|STT")\nFString LanguageCode = TEXT("en");\n\nUPROPERTY(EditAnywhere, BlueprintReadWrite, Category="ElysGenAI|STT")\nbool bEnableVAD = true;  // Voice activity detection\n\nUPROPERTY(EditAnywhere, BlueprintReadWrite, Category="ElysGenAI|STT")\nfloat MinConfidence = 0.5f;\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Project Settings:"})," Project Settings \u2192 Elys GenAI Framework \u2192 STT"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Backend: Whisper"}),"\n",(0,i.jsx)(n.li,{children:"Model Path: (empty = use bundled)"}),"\n",(0,i.jsx)(n.li,{children:"NumThreads: 4 (match CPU cores)"}),"\n",(0,i.jsx)(n.li,{children:"Enable VAD: true"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"events",children:"Events"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"OnTranscriptionComplete:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'DECLARE_DYNAMIC_MULTICAST_DELEGATE_OneParam(\n    FElysSTTResultDelegate, \n    const FERP_STTResult&, Result\n);\n\nUPROPERTY(BlueprintAssignable, Category="ElysGenAI|STT")\nFElysSTTResultDelegate OnTranscriptionComplete;\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Result Structure:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\nstruct FERP_STTResult\n{\n    UPROPERTY(BlueprintReadOnly)\n    FString TranscribedText;\n    \n    UPROPERTY(BlueprintReadOnly)\n    float Confidence;  // 0.0-1.0\n    \n    UPROPERTY(BlueprintReadOnly)\n    FString Language;\n    \n    UPROPERTY(BlueprintReadOnly)\n    bool bIsFinal;\n};\n"})}),"\n",(0,i.jsx)(n.h3,{id:"whisper-models",children:"Whisper Models"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model"}),(0,i.jsx)(n.th,{children:"Size"}),(0,i.jsx)(n.th,{children:"Use Case"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"tiny"}),(0,i.jsx)(n.td,{children:"~75 MB"}),(0,i.jsx)(n.td,{children:"Testing, prototyping"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"base.en"})}),(0,i.jsx)(n.td,{children:"~74 MB"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"Recommended"}),": English only"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"base"}),(0,i.jsx)(n.td,{children:"~142 MB"}),(0,i.jsx)(n.td,{children:"Multilingual (99+ languages)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"small"}),(0,i.jsx)(n.td,{children:"~466 MB"}),(0,i.jsx)(n.td,{children:"Better accuracy"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"medium"}),(0,i.jsx)(n.td,{children:"~1.5 GB"}),(0,i.jsx)(n.td,{children:"High accuracy"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"large"}),(0,i.jsx)(n.td,{children:"~3 GB"}),(0,i.jsx)(n.td,{children:"Best accuracy"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Supported Languages:"})," en, es, fr, de, it, pt, nl, ru, zh, ja, ko, ar, hi, and 87+ more"]}),"\n",(0,i.jsx)(n.h3,{id:"voice-activity-detection-vad",children:"Voice Activity Detection (VAD)"}),"\n",(0,i.jsx)(n.p,{children:"VAD filters silence automatically:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"STTComponent->SetEnableVAD(true);  // Enabled by default\n\n// Adjust sensitivity (0.0-1.0)\n// Higher = more aggressive filtering\nSTTComponent->SetVADThreshold(0.5f);\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"When to adjust:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Noisy environment:"})," Increase threshold (0.6-0.8)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Quiet environment:"})," Decrease threshold (0.3-0.5)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"performance-tuning",children:"Performance Tuning"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Thread Count:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// Project Settings \u2192 STT \u2192 NumThreads\n// Set to CPU core count for best performance\nNumThreads = 4;  // For quad-core CPU\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Buffer Duration:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// Project Settings \u2192 Audio \u2192 Buffer Duration\nBufferDuration = 100ms;  // Lower = less latency, higher = better accuracy\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"language-models-llm",children:"Language Models (LLM)"}),"\n",(0,i.jsx)(n.h3,{id:"quick-setup-1",children:"Quick Setup"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'// 1. Add component\nUPROPERTY(VisibleAnywhere)\nUERP_LLMComponent* LLMComponent;\n\n// 2. Set system prompt\nLLMComponent->SetSystemPrompt(TEXT("You are a friendly merchant NPC."));\n\n// 3. Bind event\nLLMComponent->OnGenerationComplete.AddDynamic(\n    this, &AMyNPC::OnDialogueGenerated);\n\n// 4. Send message\nLLMComponent->SendMessage(TEXT("What are you selling?"));\n\n// 5. Handle response\nvoid AMyNPC::OnDialogueGenerated(const FERP_LLMResult& Result)\n{\n    DisplayDialogue(Result.GeneratedText);\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"component-api-1",children:"Component API"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"SendMessage:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\nvoid SendMessage(const FString& Message);\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"SetSystemPrompt:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\nvoid SetSystemPrompt(const FString& Prompt);\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"ClearHistory:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\nvoid ClearHistory();\n'})}),"\n",(0,i.jsx)(n.h3,{id:"configuration-1",children:"Configuration"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Component Properties:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\nFString SystemPrompt = TEXT("You are a helpful assistant.");\n\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\nint32 MaxTokens = 256;\n\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\nfloat Temperature = 0.7f;  // 0.0-2.0\n\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\nint32 MaxHistoryMessages = 20;\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Project Settings:"})," Project Settings \u2192 Elys GenAI Framework \u2192 LLM"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Backend: LlamaCpp"}),"\n",(0,i.jsx)(n.li,{children:"Model Path: (empty = use bundled Phi-3)"}),"\n",(0,i.jsx)(n.li,{children:"ContextLength: 4096 tokens"}),"\n",(0,i.jsx)(n.li,{children:"NumThreads: 4"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"events-1",children:"Events"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"OnGenerationComplete:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"UPROPERTY(BlueprintAssignable)\nFERP_LLMResultDelegate OnGenerationComplete;\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Result Structure:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\nstruct FERP_LLMResult\n{\n    UPROPERTY(BlueprintReadOnly)\n    FString GeneratedText;\n    \n    UPROPERTY(BlueprintReadOnly)\n    int32 TokenCount;\n    \n    UPROPERTY(BlueprintReadOnly)\n    EElysLLMFinishReason FinishReason;  // Completed, Length, Stop\n};\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"OnTokenGenerated (Streaming):"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"UPROPERTY(BlueprintAssignable)\nFERP_LLMTokenDelegate OnTokenGenerated;\n"})}),"\n",(0,i.jsx)(n.p,{children:"Use for typewriter effects:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"LLMComponent->OnTokenGenerated.AddDynamic(this, &AMyNPC::OnToken);\n\nvoid AMyNPC::OnToken(const FString& Token)\n{\n    DialogueText += Token;\n    UpdateDialogueUI(DialogueText);\n}\n"})}),"\n",(0,i.jsx)(n.h3,{id:"bundled-model-phi-3-mini",children:"Bundled Model: Phi-3-mini"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Specs:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Size: ~2.7GB (Q4 quantized)"}),"\n",(0,i.jsx)(n.li,{children:"Context: 4096 tokens"}),"\n",(0,i.jsx)(n.li,{children:"License: MIT"}),"\n",(0,i.jsx)(n.li,{children:"Speed: ~20 tokens/sec (CPU)"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Use Cases:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"NPC dialogue"}),"\n",(0,i.jsx)(n.li,{children:"Quest generation"}),"\n",(0,i.jsx)(n.li,{children:"Item descriptions"}),"\n",(0,i.jsx)(n.li,{children:"Dynamic storytelling"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"temperature-guide",children:"Temperature Guide"}),"\n",(0,i.jsx)(n.p,{children:"Controls creativity/randomness:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// 0.0-0.3: Factual, deterministic (game mechanics, tutorials)\nLLMComponent->SetTemperature(0.3f);\n\n// 0.4-0.7: Balanced (NPC dialogue, descriptions)\nLLMComponent->SetTemperature(0.7f);\n\n// 0.8-1.5: Creative (storytelling, humor)\nLLMComponent->SetTemperature(1.2f);\n"})}),"\n",(0,i.jsx)(n.h3,{id:"system-prompt-best-practices",children:"System Prompt Best Practices"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Clear Instructions:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'FString SystemPrompt = TEXT(\n    "You are a wise wizard NPC named Gandor. "\n    "Keep responses under 50 words. "\n    "Speak in archaic English. "\n    "Never break character."\n);\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Few-Shot Examples:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'FString SystemPrompt = TEXT(\n    "You are a merchant. Examples:\\n"\n    "Player: \'What do you sell?\'\\n"\n    "You: \'Potions, weapons, and armor!\'\\n"\n    "Player: \'How much for a sword?\'\\n"\n    "You: \'100 gold pieces.\'"\n);\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"combined-examples",children:"Combined Examples"}),"\n",(0,i.jsx)(n.h3,{id:"voice-to-dialogue-pipeline",children:"Voice-to-Dialogue Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'// 1. Capture audio \u2192 2. Transcribe \u2192 3. Generate response\n\nUCLASS()\nclass AMyNPC : public AActor\n{\n    GENERATED_BODY()\n\npublic:\n    UPROPERTY(VisibleAnywhere)\n    UERP_STTComponent* STTComponent;\n    \n    UPROPERTY(VisibleAnywhere)\n    UERP_LLMComponent* LLMComponent;\n\nprotected:\n    virtual void BeginPlay() override\n    {\n        Super::BeginPlay();\n        \n        // Setup STT\n        STTComponent->SetLanguageCode(TEXT("en"));\n        STTComponent->SetAutoStartListening(true);\n        STTComponent->OnTranscriptionComplete.AddDynamic(\n            this, &AMyNPC::OnPlayerSpoke);\n        \n        // Setup LLM\n        LLMComponent->SetSystemPrompt(TEXT("You are a friendly merchant."));\n        LLMComponent->OnGenerationComplete.AddDynamic(\n            this, &AMyNPC::OnDialogueGenerated);\n    }\n    \n    UFUNCTION()\n    void OnPlayerSpoke(const FERP_STTResult& Result)\n    {\n        // Send transcription to LLM\n        LLMComponent->SendMessage(Result.TranscribedText);\n    }\n    \n    UFUNCTION()\n    void OnDialogueGenerated(const FERP_LLMResult& Result)\n    {\n        // Display NPC response\n        DisplayDialogue(Result.GeneratedText);\n    }\n};\n'})}),"\n",(0,i.jsx)(n.h3,{id:"multi-consumer-audio-routing",children:"Multi-Consumer Audio Routing"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// Route audio to both STT and voice chat\n\nUCLASS()\nclass AMyPlayerController : public APlayerController\n{\n    GENERATED_BODY()\n\npublic:\n    UPROPERTY(VisibleAnywhere)\n    UERP_STTComponent* STTComponent;\n    \n    UPROPERTY(VisibleAnywhere)\n    UVoiceChatComponent* VoiceChatComponent;\n\nprotected:\n    virtual void BeginPlay() override\n    {\n        Super::BeginPlay();\n        \n        // Both components automatically register as audio consumers\n        // Audio flows to both simultaneously\n        STTComponent->StartListening();\n        VoiceChatComponent->StartTransmitting();\n    }\n};\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"settings-reference",children:"Settings Reference"}),"\n",(0,i.jsx)(n.h3,{id:"audio-settings",children:"Audio Settings"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Setting"}),(0,i.jsx)(n.th,{children:"Default"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Sample Rate"}),(0,i.jsx)(n.td,{children:"16000 Hz"}),(0,i.jsx)(n.td,{children:"Audio capture sample rate"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Channels"}),(0,i.jsx)(n.td,{children:"1 (Mono)"}),(0,i.jsx)(n.td,{children:"Audio channels"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Bit Depth"}),(0,i.jsx)(n.td,{children:"16"}),(0,i.jsx)(n.td,{children:"Audio bit depth"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Buffer Duration"}),(0,i.jsx)(n.td,{children:"100ms"}),(0,i.jsx)(n.td,{children:"Audio buffer size"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"stt-settings",children:"STT Settings"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Setting"}),(0,i.jsx)(n.th,{children:"Default"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"STT Backend"}),(0,i.jsx)(n.td,{children:"Whisper"}),(0,i.jsx)(n.td,{children:"Backend implementation"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Model Path"}),(0,i.jsx)(n.td,{children:"(bundled)"}),(0,i.jsx)(n.td,{children:"Path to Whisper model"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Language"}),(0,i.jsx)(n.td,{children:"en"}),(0,i.jsx)(n.td,{children:"Target language code"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Enable VAD"}),(0,i.jsx)(n.td,{children:"true"}),(0,i.jsx)(n.td,{children:"Voice activity detection"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Num Threads"}),(0,i.jsx)(n.td,{children:"4"}),(0,i.jsx)(n.td,{children:"Inference threads"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"llm-settings",children:"LLM Settings"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Setting"}),(0,i.jsx)(n.th,{children:"Default"}),(0,i.jsx)(n.th,{children:"Description"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"LLM Backend"}),(0,i.jsx)(n.td,{children:"LlamaCpp"}),(0,i.jsx)(n.td,{children:"Backend implementation"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Model Path"}),(0,i.jsx)(n.td,{children:"(bundled)"}),(0,i.jsx)(n.td,{children:"Path to Phi-3 model"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Context Length"}),(0,i.jsx)(n.td,{children:"4096"}),(0,i.jsx)(n.td,{children:"Maximum context tokens"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Temperature"}),(0,i.jsx)(n.td,{children:"0.7"}),(0,i.jsx)(n.td,{children:"Sampling temperature"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Max Tokens"}),(0,i.jsx)(n.td,{children:"512"}),(0,i.jsx)(n.td,{children:"Maximum generation length"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Num Threads"}),(0,i.jsx)(n.td,{children:"4"}),(0,i.jsx)(n.td,{children:"Inference threads"})]})]})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/ElysGenAIPlugin/Examples",children:"Examples"})})," - Practical implementation recipes"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/ElysGenAIPlugin/API-Reference",children:"API Reference"})})," - Complete class documentation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/ElysGenAIPlugin/Troubleshooting",children:"Troubleshooting"})})," - Common issues and solutions"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453(e,n,t){t.d(n,{R:()=>l,x:()=>d});var s=t(6540);const i={},r=s.createContext(i);function l(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);