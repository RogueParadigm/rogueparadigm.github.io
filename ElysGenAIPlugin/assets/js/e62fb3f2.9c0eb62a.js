"use strict";(globalThis.webpackChunkelysgenai_docs=globalThis.webpackChunkelysgenai_docs||[]).push([[839],{9781(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"Examples","title":"Examples","description":"Practical recipes for using ElysGenAI in your game.","source":"@site/../Documentation/Examples.md","sourceDirName":".","slug":"/Examples","permalink":"/ElysGenAIPlugin/Examples","draft":false,"unlisted":false,"editUrl":"https://github.com/RogueParadigm/ElysGenAIPlugin/tree/main/Documentation/../Documentation/Examples.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"id":"Examples","title":"Examples","sidebar_position":5},"sidebar":"docsSidebar","previous":{"title":"Modules Guide","permalink":"/ElysGenAIPlugin/ModulesGuide"},"next":{"title":"API Reference","permalink":"/ElysGenAIPlugin/API-Reference"}}');var i=t(4848),s=t(8453);const r={id:"Examples",title:"Examples",sidebar_position:5},a="Examples",l={},c=[{value:"Recipe 1: Voice Command System",id:"recipe-1-voice-command-system",level:2},{value:"Recipe 1.5: Voice-to-LLM Pipeline (Blueprint)",id:"recipe-15-voice-to-llm-pipeline-blueprint",level:2},{value:"Recipe 2: NPC Dialogue",id:"recipe-2-npc-dialogue",level:2},{value:"Recipe 3: Multiplayer Voice Chat with Subtitles",id:"recipe-3-multiplayer-voice-chat-with-subtitles",level:2},{value:"Recipe 4: Push-to-Talk Voice Commands",id:"recipe-4-push-to-talk-voice-commands",level:2},{value:"Recipe 5: Custom Audio Consumer",id:"recipe-5-custom-audio-consumer",level:2},{value:"Recipe 6: Custom STT Backend",id:"recipe-6-custom-stt-backend",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"examples",children:"Examples"})}),"\n",(0,i.jsx)(e.p,{children:"Practical recipes for using ElysGenAI in your game."}),"\n",(0,i.jsx)(e.h2,{id:"recipe-1-voice-command-system",children:"Recipe 1: Voice Command System"}),"\n",(0,i.jsx)(e.p,{children:"Build a voice-controlled player controller."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:'// PlayerController.h\nUCLASS()\nclass AMyPlayerController : public APlayerController\n{\n    GENERATED_BODY()\n    \n    UPROPERTY(VisibleAnywhere)\n    UERP_STTComponent* STTComponent;\n    \n    UFUNCTION()\n    void OnVoiceCommand(const FERP_STTResult& Result);\n};\n\n// PlayerController.cpp\nvoid AMyPlayerController::BeginPlay()\n{\n    Super::BeginPlay();\n    \n    if (IsLocalController())\n    {\n        STTComponent->SetLanguageCode(TEXT("en"));\n        STTComponent->OnTranscriptionComplete.AddDynamic(\n            this, &AMyPlayerController::OnVoiceCommand);\n        STTComponent->StartListening();\n    }\n}\n\nvoid AMyPlayerController::OnVoiceCommand(const FERP_STTResult& Result)\n{\n    if (Result.Confidence < 0.7f) return;\n    \n    FString Command = Result.TranscribedText.ToLower();\n    \n    if (Command.Contains(TEXT("attack")))\n    {\n        Cast<AMyCharacter>(GetPawn())->PerformAttack();\n    }\n    else if (Command.Contains(TEXT("inventory")))\n    {\n        OpenInventoryUI();\n    }\n    else if (Command.Contains(TEXT("map")))\n    {\n        ToggleMap();\n    }\n}\n'})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"recipe-15-voice-to-llm-pipeline-blueprint",children:"Recipe 1.5: Voice-to-LLM Pipeline (Blueprint)"}),"\n",(0,i.jsx)(e.p,{children:"Build an AI assistant that listens to your voice and responds using LLM."}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Blueprint Event Graph Flow:"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{children:"[Event BeginPlay]\n  \u2193\n[Add STT Component]\n  \u2193\n[Add LLM Component]\n  \u2193\n[Bind STT OnTranscriptionComplete \u2192 OnPlayerSpoke]\n  \u2193\n[Bind LLM OnGenerationComplete \u2192 OnLLMResponse]\n  \u2193\n[STT Component \u2192 Start Listening]\n\n[Custom Event: OnPlayerSpoke]\n  \u2193\n[STT Result \u2192 Get Transcribed Text]\n  \u2193\n[LLM Component \u2192 Send Message]\n\n[Custom Event: OnLLMResponse]\n  \u2193\n[LLM Result \u2192 Get Generated Text]\n  \u2193\n[Display Text / Play Audio]\n"})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"C++ Implementation:"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:'// VoiceAssistantComponent.h\nUCLASS()\nclass UVoiceAssistantComponent : public UActorComponent\n{\n    GENERATED_BODY()\n\n    UPROPERTY(VisibleAnywhere)\n    UERP_STTComponent* STTComponent;\n\n    UPROPERTY(VisibleAnywhere)\n    UERP_LLMComponent* LLMComponent;\n\n    UFUNCTION()\n    void OnPlayerSpoke(const FERP_STTResult& Result);\n\n    UFUNCTION()\n    void OnLLMResponse(const FERP_LLMResult& Result);\n};\n\n// VoiceAssistantComponent.cpp\nvoid UVoiceAssistantComponent::BeginPlay()\n{\n    Super::BeginPlay();\n\n    // Create STT component if not assigned\n    if (!STTComponent)\n    {\n        STTComponent = NewObject<UERP_STTComponent>();\n        STTComponent->RegisterComponent();\n    }\n\n    // Create LLM component if not assigned\n    if (!LLMComponent)\n    {\n        LLMComponent = NewObject<UERP_LLMComponent>();\n        LLMComponent->RegisterComponent();\n    }\n\n    // Configure LLM with system prompt\n    LLMComponent->SetSystemPrompt(TEXT(\n        "You are a helpful AI assistant in a video game. "\n        "Keep responses concise (1-2 sentences). "\n        "Be friendly and natural."));\n    LLMComponent->SetTemperature(0.7f);\n    LLMComponent->SetMaxTokens(128);\n\n    // Bind events\n    STTComponent->OnTranscriptionComplete.AddDynamic(\n        this, &UVoiceAssistantComponent::OnPlayerSpoke);\n    LLMComponent->OnGenerationComplete.AddDynamic(\n        this, &UVoiceAssistantComponent::OnLLMResponse);\n\n    // Start listening\n    STTComponent->StartListening();\n    UE_LOG(LogTemp, Log, TEXT("Voice Assistant: Listening for speech..."));\n}\n\nvoid UVoiceAssistantComponent::OnPlayerSpoke(const FERP_STTResult& Result)\n{\n    if (Result.Confidence < 0.6f)\n    {\n        UE_LOG(LogTemp, Warning, TEXT("Low confidence: %s"), *Result.TranscribedText);\n        return;\n    }\n\n    UE_LOG(LogTemp, Log, TEXT("You said: %s"), *Result.TranscribedText);\n\n    // Send player\'s speech to LLM\n    LLMComponent->SendMessage(Result.TranscribedText);\n}\n\nvoid UVoiceAssistantComponent::OnLLMResponse(const FERP_LLMResult& Result)\n{\n    UE_LOG(LogTemp, Log, TEXT("Assistant: %s"), *Result.GeneratedText);\n\n    // Optional: Play text-to-speech audio of response\n    // PlayResponseAudio(Result.GeneratedText);\n\n    // Resume listening for next message\n    STTComponent->StartListening();\n}\n'})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Usage:"})}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsxs)(e.li,{children:["Add ",(0,i.jsx)(e.code,{children:"UVoiceAssistantComponent"})," to your PlayerController or Character"]}),"\n",(0,i.jsx)(e.li,{children:"Player speaks into microphone"}),"\n",(0,i.jsx)(e.li,{children:"Speech is transcribed to text (STT)"}),"\n",(0,i.jsx)(e.li,{children:"Text is sent to LLM for processing"}),"\n",(0,i.jsx)(e.li,{children:"LLM generates response"}),"\n",(0,i.jsx)(e.li,{children:"Response is logged and can be displayed/spoken"}),"\n"]}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"recipe-2-npc-dialogue",children:"Recipe 2: NPC Dialogue"}),"\n",(0,i.jsx)(e.p,{children:"Create an interactive merchant NPC with LLM-powered dialogue."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:'// MerchantNPC.h\nUCLASS()\nclass AMerchantNPC : public ACharacter\n{\n    GENERATED_BODY()\n    \n    UPROPERTY(VisibleAnywhere)\n    UERP_LLMComponent* LLMComponent;\n    \n    UPROPERTY(VisibleAnywhere)\n    UWidgetComponent* DialogueWidget;\n    \n    void InitializePersonality();\n    \n    UFUNCTION(BlueprintCallable)\n    void StartConversation(AActor* Player);\n    \n    UFUNCTION()\n    void OnResponseGenerated(const FERP_LLMResult& Result);\n};\n\n// MerchantNPC.cpp\nvoid AMerchantNPC::BeginPlay()\n{\n    Super::BeginPlay();\n    InitializePersonality();\n    \n    LLMComponent->OnGenerationComplete.AddDynamic(\n        this, &AMerchantNPC::OnResponseGenerated);\n}\n\nvoid AMerchantNPC::InitializePersonality()\n{\n    FString Personality = FString::Printf(\n        TEXT("You are %s, a merchant in a medieval fantasy town. "\n             "You sell weapons, armor, and supplies. "\n             "You\'re friendly but shrewd about prices. "\n             "Keep responses under 50 words."),\n        *GetName());\n    \n    LLMComponent->SetSystemPrompt(Personality);\n    LLMComponent->SetTemperature(0.75f);\n    LLMComponent->SetMaxTokens(80);\n}\n\nvoid AMerchantNPC::StartConversation(AActor* Player)\n{\n    // Get player\'s STT component\n    if (UERP_STTComponent* PlayerSTT = \n        Player->FindComponentByClass<UERP_STTComponent>())\n    {\n        PlayerSTT->OnTranscriptionComplete.AddDynamic(\n            this, &AMerchantNPC::OnPlayerSpoke);\n    }\n    \n    // Greeting\n    LLMComponent->SendMessage(TEXT("Greet the player warmly."));\n}\n\nvoid AMerchantNPC::OnPlayerSpoke(const FERP_STTResult& Result)\n{\n    // Player spoke, generate response\n    LLMComponent->SendMessage(Result.TranscribedText);\n}\n\nvoid AMerchantNPC::OnResponseGenerated(const FERP_LLMResult& Result)\n{\n    // Display dialogue bubble\n    DialogueWidget->SetText(FText::FromString(Result.GeneratedText));\n}\n'})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"recipe-3-multiplayer-voice-chat-with-subtitles",children:"Recipe 3: Multiplayer Voice Chat with Subtitles"}),"\n",(0,i.jsx)(e.p,{children:"Voice chat that automatically generates subtitles using STT."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:"// VoiceChatComponent.h\nUCLASS()\nclass UVoiceChatComponent : public UActorComponent, public IERP_AudioConsumer\n{\n    GENERATED_BODY()\n    \n    UPROPERTY(VisibleAnywhere)\n    UERP_STTComponent* STTComponent;\n    \n    // IERP_AudioConsumer\n    virtual void OnAudioDataReceived_Implementation(const FERP_AudioBuffer& Buffer) override;\n    \n    UFUNCTION(Server, Unreliable, WithValidation)\n    void ServerStreamAudio(const TArray<uint8>& CompressedAudio);\n    \n    UFUNCTION(Server, Reliable, WithValidation)\n    void ServerSendTranscription(const FString& Text);\n    \n    UFUNCTION(NetMulticast, Reliable)\n    void MulticastDisplaySubtitles(APlayerController* Speaker, const FString& Text);\n};\n\n// VoiceChatComponent.cpp\nvoid UVoiceChatComponent::BeginPlay()\n{\n    Super::BeginPlay();\n    \n    if (IsLocallyControlled())\n    {\n        // Register as audio consumer\n        UERP_AudioCaptureSubsystem* AudioSubsystem = \n            GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n        AudioSubsystem->RegisterConsumer(this);\n        \n        // Setup STT for subtitles\n        STTComponent->OnTranscriptionComplete.AddDynamic(\n            this, &UVoiceChatComponent::OnTranscription);\n    }\n}\n\nvoid UVoiceChatComponent::OnAudioDataReceived_Implementation(const FERP_AudioBuffer& Buffer)\n{\n    // Compress audio (Opus codec)\n    TArray<uint8> Compressed = CompressAudioOpus(Buffer.AudioData);\n    \n    // Send to server (audio only, NOT replicated)\n    ServerStreamAudio(Compressed);\n}\n\nvoid UVoiceChatComponent::OnTranscription(const FERP_STTResult& Result)\n{\n    // Send transcription to server\n    ServerSendTranscription(Result.TranscribedText);\n}\n\nvoid UVoiceChatComponent::ServerSendTranscription_Implementation(const FString& Text)\n{\n    // Broadcast subtitles to all clients\n    MulticastDisplaySubtitles(GetOwner<APlayerController>(), Text);\n}\n\nvoid UVoiceChatComponent::MulticastDisplaySubtitles_Implementation(\n    APlayerController* Speaker, const FString& Text)\n{\n    // Display subtitle widget for this player\n    ShowSubtitle(Speaker, Text);\n}\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"recipe-4-push-to-talk-voice-commands",children:"Recipe 4: Push-to-Talk Voice Commands"}),"\n",(0,i.jsx)(e.p,{children:"Voice commands with push-to-talk input binding."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:'// PlayerController.h\nUCLASS()\nclass AMyPlayerController : public APlayerController\n{\n    GENERATED_BODY()\n    \n    UPROPERTY(VisibleAnywhere)\n    UERP_STTComponent* STTComponent;\n    \n    void StartVoiceCapture();\n    void StopVoiceCapture();\n    \n    UFUNCTION()\n    void OnCommandReceived(const FERP_STTResult& Result);\n};\n\n// PlayerController.cpp\nvoid AMyPlayerController::SetupInputComponent()\n{\n    Super::SetupInputComponent();\n    \n    // Bind push-to-talk key\n    InputComponent->BindAction("VoiceCommand", IE_Pressed, \n        this, &AMyPlayerController::StartVoiceCapture);\n    InputComponent->BindAction("VoiceCommand", IE_Released, \n        this, &AMyPlayerController::StopVoiceCapture);\n}\n\nvoid AMyPlayerController::StartVoiceCapture()\n{\n    auto* AudioSubsystem = GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n    AudioSubsystem->SetPushToTalkActive(true);\n    \n    // Visual feedback\n    ShowVoiceIndicator(true);\n}\n\nvoid AMyPlayerController::StopVoiceCapture()\n{\n    auto* AudioSubsystem = GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n    AudioSubsystem->SetPushToTalkActive(false);\n    \n    ShowVoiceIndicator(false);\n}\n'})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"recipe-5-custom-audio-consumer",children:"Recipe 5: Custom Audio Consumer"}),"\n",(0,i.jsx)(e.p,{children:"Record audio to file using the consumer pattern."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:'// AudioRecorderComponent.h\nUCLASS()\nclass UAudioRecorderComponent : public UActorComponent, public IERP_AudioConsumer\n{\n    GENERATED_BODY()\n    \npublic:\n    UFUNCTION(BlueprintCallable)\n    void StartRecording(const FString& Filename);\n    \n    UFUNCTION(BlueprintCallable)\n    void StopRecording();\n    \n    // IERP_AudioConsumer\n    virtual void OnAudioDataReceived_Implementation(const FERP_AudioBuffer& Buffer) override;\n    virtual FString GetConsumerName_Implementation() const override;\n    \nprivate:\n    bool bIsRecording = false;\n    TArray<float> RecordedAudio;\n    FString OutputFilename;\n};\n\n// AudioRecorderComponent.cpp\nvoid UAudioRecorderComponent::BeginPlay()\n{\n    Super::BeginPlay();\n    \n    // Register as consumer\n    auto* AudioSubsystem = GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\n    AudioSubsystem->RegisterConsumer(this);\n}\n\nvoid UAudioRecorderComponent::StartRecording(const FString& Filename)\n{\n    bIsRecording = true;\n    OutputFilename = Filename;\n    RecordedAudio.Empty();\n}\n\nvoid UAudioRecorderComponent::StopRecording()\n{\n    bIsRecording = false;\n    \n    // Save to WAV file\n    SaveAudioToWAV(RecordedAudio, OutputFilename);\n}\n\nvoid UAudioRecorderComponent::OnAudioDataReceived_Implementation(const FERP_AudioBuffer& Buffer)\n{\n    if (bIsRecording)\n    {\n        RecordedAudio.Append(Buffer.AudioData);\n    }\n}\n\nFString UAudioRecorderComponent::GetConsumerName_Implementation() const\n{\n    return TEXT("AudioRecorder");\n}\n'})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"recipe-6-custom-stt-backend",children:"Recipe 6: Custom STT Backend"}),"\n",(0,i.jsx)(e.p,{children:"Implement a custom STT backend for alternative models."}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:'// MyCustomSTTBackend.h\nUCLASS()\nclass UMyCustomSTTBackend : public UObject, public IERP_STTBackend\n{\n    GENERATED_BODY()\n    \npublic:\n    // IERP_GenAIService interface\n    virtual bool Initialize() override;\n    virtual void Shutdown() override;\n    virtual bool IsReady() const override;\n    \n    // IERP_STTBackend interface\n    virtual bool LoadModel(const FString& ModelPath) override;\n    virtual void UnloadModel() override;\n    virtual bool IsModelLoaded() const override;\n    virtual void SetLanguage(const FString& LanguageCode) override;\n    virtual void SetSampleRate(int32 SampleRate) override;\n    virtual FERP_STTResult ProcessAudio(const TArray<float>& AudioData) override;\n    virtual void ProcessAudioAsync(const TArray<float>& AudioData, \n                                    const FElysSTTResultDelegate& Callback) override;\n    \nprivate:\n    bool bIsInitialized = false;\n    bool bModelLoaded = false;\n    FString CurrentLanguage;\n    int32 CurrentSampleRate;\n    void* CustomSTTEngine;\n};\n\n// MyCustomSTTBackend.cpp\nbool UMyCustomSTTBackend::Initialize()\n{\n    CustomSTTEngine = CreateYourSTTEngine();\n    bIsInitialized = (CustomSTTEngine != nullptr);\n    return bIsInitialized;\n}\n\nbool UMyCustomSTTBackend::LoadModel(const FString& ModelPath)\n{\n    if (!bIsInitialized) return false;\n    \n    bModelLoaded = YourSTTEngine_LoadModel(CustomSTTEngine, ModelPath);\n    return bModelLoaded;\n}\n\nFERP_STTResult UMyCustomSTTBackend::ProcessAudio(const TArray<float>& AudioData)\n{\n    FERP_STTResult Result;\n    \n    if (!IsReady())\n    {\n        Result.TranscribedText = TEXT("");\n        Result.Confidence = 0.0f;\n        return Result;\n    }\n    \n    FString Transcription = YourSTTEngine_Transcribe(CustomSTTEngine, AudioData);\n    float Confidence = YourSTTEngine_GetConfidence(CustomSTTEngine);\n    \n    Result.TranscribedText = Transcription;\n    Result.Confidence = Confidence;\n    Result.Language = CurrentLanguage;\n    Result.bIsFinal = true;\n    \n    return Result;\n}\n'})}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Register in Subsystem:"})}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-cpp",children:"// In UERP_STTSubsystem\nTScriptInterface<IERP_STTBackend> UERP_STTSubsystem::CreateBackend()\n{\n    UMyCustomSTTBackend* CustomBackend = NewObject<UMyCustomSTTBackend>(this);\n    \n    TScriptInterface<IERP_STTBackend> BackendInterface;\n    BackendInterface.SetObject(CustomBackend);\n    BackendInterface.SetInterface(Cast<IERP_STTBackend>(CustomBackend));\n    \n    return BackendInterface;\n}\n"})}),"\n",(0,i.jsx)(e.hr,{}),"\n",(0,i.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:(0,i.jsx)(e.a,{href:"/ElysGenAIPlugin/API-Reference",children:"API Reference"})})," - Complete class documentation"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:(0,i.jsx)(e.a,{href:"/ElysGenAIPlugin/Troubleshooting",children:"Troubleshooting"})})," - Common issues and solutions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:(0,i.jsx)(e.a,{href:"/ElysGenAIPlugin/MultiplayerGuide",children:"Multiplayer Guide"})})," - Network architecture best practices"]}),"\n"]})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(d,{...n})}):d(n)}},8453(n,e,t){t.d(e,{R:()=>r,x:()=>a});var o=t(6540);const i={},s=o.createContext(i);function r(n){const e=o.useContext(s);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:r(n.components),o.createElement(s.Provider,{value:e},n.children)}}}]);