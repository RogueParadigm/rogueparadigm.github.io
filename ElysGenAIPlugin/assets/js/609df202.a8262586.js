"use strict";(globalThis.webpackChunkelysgenai_docs=globalThis.webpackChunkelysgenai_docs||[]).push([[208],{3648(e,n,r){r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>d,default:()=>u,frontMatter:()=>l,metadata:()=>t,toc:()=>a});const t=JSON.parse('{"id":"ModulesGuide","title":"Modules Guide","description":"Complete guide to Audio Capture, Speech-to-Text, and Language Models.","source":"@site/../Documentation/ModulesGuide.md","sourceDirName":".","slug":"/ModulesGuide","permalink":"/ElysGenAIPlugin/ModulesGuide","draft":false,"unlisted":false,"editUrl":"https://github.com/RogueParadigm/ElysGenAIPlugin/tree/main/Documentation/../Documentation/ModulesGuide.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"id":"ModulesGuide","title":"Modules Guide","sidebar_position":4},"sidebar":"docsSidebar","previous":{"title":"Core Concepts","permalink":"/ElysGenAIPlugin/CoreConcepts"},"next":{"title":"Examples","permalink":"/ElysGenAIPlugin/Examples"}}');var s=r(4848),i=r(8453);const l={id:"ModulesGuide",title:"Modules Guide",sidebar_position:4},d="Modules Guide",o={},a=[{value:"Overview",id:"overview",level:2},{value:"Audio Capture System",id:"audio-capture-system",level:2},{value:"Quick Start",id:"quick-start",level:3},{value:"Consumer Pattern",id:"consumer-pattern",level:3},{value:"Register Consumer",id:"register-consumer",level:3},{value:"Push-to-Talk Modes",id:"push-to-talk-modes",level:3},{value:"Audio Formats",id:"audio-formats",level:3},{value:"Mute Control",id:"mute-control",level:3},{value:"Speech-to-Text (STT)",id:"speech-to-text-stt",level:2},{value:"Quick Setup",id:"quick-setup",level:3},{value:"Component API",id:"component-api",level:3},{value:"Configuration",id:"configuration",level:3},{value:"Events",id:"events",level:3},{value:"Whisper Models",id:"whisper-models",level:3},{value:"Voice Activity Detection (VAD)",id:"voice-activity-detection-vad",level:3},{value:"Performance Tuning",id:"performance-tuning",level:3},{value:"Language Models (LLM)",id:"language-models-llm",level:2},{value:"Quick Setup",id:"quick-setup-1",level:3},{value:"Component API",id:"component-api-1",level:3},{value:"Configuration",id:"configuration-1",level:3},{value:"Events",id:"events-1",level:3},{value:"Bundled Model: Phi-3-mini",id:"bundled-model-phi-3-mini",level:3},{value:"Temperature Guide",id:"temperature-guide",level:3},{value:"System Prompt Best Practices",id:"system-prompt-best-practices",level:3},{value:"Combined Examples",id:"combined-examples",level:2},{value:"Voice-to-Dialogue Pipeline",id:"voice-to-dialogue-pipeline",level:3},{value:"Multi-Consumer Audio Routing",id:"multi-consumer-audio-routing",level:3},{value:"Settings Reference",id:"settings-reference",level:2},{value:"Audio Settings",id:"audio-settings",level:3},{value:"STT Settings",id:"stt-settings",level:3},{value:"LLM Settings",id:"llm-settings",level:3},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"modules-guide",children:"Modules Guide"})}),"\n",(0,s.jsx)(n.p,{children:"Complete guide to Audio Capture, Speech-to-Text, and Language Models."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"ElysGenAI provides three integrated modules:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Microphone \u2192 Audio Capture \u2192 STT \u2192 Transcribed Text \u2192 LLM \u2192 Generated Response\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Modules:"})}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Audio Capture"})," - Microphone input and routing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"STT"})," - Speech-to-text using Whisper"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"LLM"})," - Language models using Phi-3-mini"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"audio-capture-system",children:"Audio Capture System"}),"\n",(0,s.jsx)(n.h3,{id:"quick-start",children:"Quick Start"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// Get subsystem\r\nUERP_AudioCaptureSubsystem* AudioSubsystem = \r\n    GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\r\n\r\n// Start capturing\r\nAudioSubsystem->StartCapture();\n"})}),"\n",(0,s.jsx)(n.h3,{id:"consumer-pattern",children:"Consumer Pattern"}),"\n",(0,s.jsxs)(n.p,{children:["Implement ",(0,s.jsx)(n.code,{children:"IERP_AudioConsumer"})," to receive audio:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UCLASS()\r\nclass UMyAudioConsumer : public UObject, public IERP_AudioConsumer\r\n{\r\n    GENERATED_BODY()\r\n    \r\npublic:\r\n    virtual void OnAudioDataReceived_Implementation(const FElysAudioBuffer& Buffer) override\r\n    {\r\n        // Process audio\r\n        ProcessAudio(Buffer.AudioData);\r\n    }\r\n    \r\n    virtual FString GetConsumerName_Implementation() const override\r\n    {\r\n        return TEXT("MyAudioConsumer");\r\n    }\r\n};\n'})}),"\n",(0,s.jsx)(n.h3,{id:"register-consumer",children:"Register Consumer"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"void UMyComponent::BeginPlay()\r\n{\r\n    Super::BeginPlay();\r\n    \r\n    UERP_AudioCaptureSubsystem* AudioSubsystem = \r\n        GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\r\n    \r\n    if (AudioSubsystem)\r\n    {\r\n        AudioSubsystem->RegisterConsumer(this);\r\n    }\r\n}\r\n\r\nvoid UMyComponent::EndPlay(const EEndPlayReason::Type Reason)\r\n{\r\n    if (UERP_AudioCaptureSubsystem* AudioSubsystem = \r\n        GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>())\r\n    {\r\n        AudioSubsystem->UnregisterConsumer(this);\r\n    }\r\n    \r\n    Super::EndPlay(Reason);\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"push-to-talk-modes",children:"Push-to-Talk Modes"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"UENUM(BlueprintType)\r\nenum class EElysPushToTalkMode : uint8\r\n{\r\n    AlwaysOn,      // Continuous capture\r\n    PushToTalk,    // Hold key to talk\r\n    PushToMute     // Hold key to mute\r\n};\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Configuration:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"AudioSubsystem->SetPushToTalkMode(EElysPushToTalkMode::PushToTalk);\r\nAudioSubsystem->SetPushToTalkActive(true); // Key pressed\r\nAudioSubsystem->SetPushToTalkActive(false); // Key released\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Input Binding:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'// In PlayerController\r\nvoid AMyPlayerController::SetupInputComponent()\r\n{\r\n    Super::SetupInputComponent();\r\n    \r\n    InputComponent->BindAction("VoiceChat", IE_Pressed, this, &AMyPlayerController::StartVoiceChat);\r\n    InputComponent->BindAction("VoiceChat", IE_Released, this, &AMyPlayerController::StopVoiceChat);\r\n}\r\n\r\nvoid AMyPlayerController::StartVoiceChat()\r\n{\r\n    auto* AudioSubsystem = GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\r\n    AudioSubsystem->SetPushToTalkActive(true);\r\n}\r\n\r\nvoid AMyPlayerController::StopVoiceChat()\r\n{\r\n    auto* AudioSubsystem = GetGameInstance()->GetSubsystem<UERP_AudioCaptureSubsystem>();\r\n    AudioSubsystem->SetPushToTalkActive(false);\r\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"audio-formats",children:"Audio Formats"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\r\nstruct FElysAudioFormat\r\n{\r\n    int32 SampleRate;   // 16000 (STT), 48000 (voice chat)\r\n    int32 NumChannels;  // 1 (mono), 2 (stereo)\r\n    int32 BitDepth;     // 16\r\n};\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"STT Default:"})," 16kHz mono 16-bit\r\n",(0,s.jsx)(n.strong,{children:"Voice Chat Default:"})," 48kHz stereo 16-bit"]}),"\n",(0,s.jsx)(n.h3,{id:"mute-control",children:"Mute Control"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// Mute microphone\r\nAudioSubsystem->SetMuted(true);\r\n\r\n// Check mute status\r\nbool bIsMuted = AudioSubsystem->IsMuted();\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"speech-to-text-stt",children:"Speech-to-Text (STT)"}),"\n",(0,s.jsx)(n.h3,{id:"quick-setup",children:"Quick Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'// 1. Add component to Actor\r\nUPROPERTY(VisibleAnywhere, BlueprintReadOnly)\r\nUERP_STTComponent* STTComponent;\r\n\r\n// 2. Bind event\r\nSTTComponent->OnTranscriptionComplete.AddDynamic(\r\n    this, &AMyActor::OnTranscriptionReceived);\r\n\r\n// 3. Start listening\r\nSTTComponent->StartListening();\r\n\r\n// 4. Handle results\r\nvoid AMyActor::OnTranscriptionReceived(const FElysSTTResult& Result)\r\n{\r\n    UE_LOG(LogTemp, Log, TEXT("Transcription: %s"), *Result.TranscribedText);\r\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"component-api",children:"Component API"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"StartListening:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|STT")\r\nvoid StartListening();\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"StopListening:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|STT")\r\nvoid StopListening();\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"IsListening:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintPure, Category="ElysGenAI|STT")\r\nbool IsListening() const;\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"SetLanguageCode:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|STT")\r\nvoid SetLanguageCode(const FString& LanguageCode);\n'})}),"\n",(0,s.jsx)(n.h3,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Component Properties:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UPROPERTY(EditAnywhere, BlueprintReadWrite, Category="ElysGenAI|STT")\r\nbool bAutoStartListening = false;\r\n\r\nUPROPERTY(EditAnywhere, BlueprintReadWrite, Category="ElysGenAI|STT")\r\nFString LanguageCode = TEXT("en");\r\n\r\nUPROPERTY(EditAnywhere, BlueprintReadWrite, Category="ElysGenAI|STT")\r\nbool bEnableVAD = true;  // Voice activity detection\r\n\r\nUPROPERTY(EditAnywhere, BlueprintReadWrite, Category="ElysGenAI|STT")\r\nfloat MinConfidence = 0.5f;\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Project Settings:"})," Project Settings \u2192 Elys GenAI Framework \u2192 STT"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Backend: Whisper"}),"\n",(0,s.jsx)(n.li,{children:"Model Path: (empty = use bundled)"}),"\n",(0,s.jsx)(n.li,{children:"NumThreads: 4 (match CPU cores)"}),"\n",(0,s.jsx)(n.li,{children:"Enable VAD: true"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"events",children:"Events"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"OnTranscriptionComplete:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'DECLARE_DYNAMIC_MULTICAST_DELEGATE_OneParam(\r\n    FElysSTTResultDelegate, \r\n    const FElysSTTResult&, Result\r\n);\r\n\r\nUPROPERTY(BlueprintAssignable, Category="ElysGenAI|STT")\r\nFElysSTTResultDelegate OnTranscriptionComplete;\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Result Structure:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\r\nstruct FElysSTTResult\r\n{\r\n    UPROPERTY(BlueprintReadOnly)\r\n    FString TranscribedText;\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    float Confidence;  // 0.0-1.0\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    FString Language;\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    bool bIsFinal;\r\n};\n"})}),"\n",(0,s.jsx)(n.h3,{id:"whisper-models",children:"Whisper Models"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Model"}),(0,s.jsx)(n.th,{children:"Size"}),(0,s.jsx)(n.th,{children:"Use Case"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"tiny"}),(0,s.jsx)(n.td,{children:"~75 MB"}),(0,s.jsx)(n.td,{children:"Testing, prototyping"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"base.en"})}),(0,s.jsx)(n.td,{children:"~74 MB"}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.strong,{children:"Recommended"}),": English only"]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"base"}),(0,s.jsx)(n.td,{children:"~142 MB"}),(0,s.jsx)(n.td,{children:"Multilingual (99+ languages)"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"small"}),(0,s.jsx)(n.td,{children:"~466 MB"}),(0,s.jsx)(n.td,{children:"Better accuracy"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"medium"}),(0,s.jsx)(n.td,{children:"~1.5 GB"}),(0,s.jsx)(n.td,{children:"High accuracy"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"large"}),(0,s.jsx)(n.td,{children:"~3 GB"}),(0,s.jsx)(n.td,{children:"Best accuracy"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Supported Languages:"})," en, es, fr, de, it, pt, nl, ru, zh, ja, ko, ar, hi, and 87+ more"]}),"\n",(0,s.jsx)(n.h3,{id:"voice-activity-detection-vad",children:"Voice Activity Detection (VAD)"}),"\n",(0,s.jsx)(n.p,{children:"VAD filters silence automatically:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"STTComponent->SetEnableVAD(true);  // Enabled by default\r\n\r\n// Adjust sensitivity (0.0-1.0)\r\n// Higher = more aggressive filtering\r\nSTTComponent->SetVADThreshold(0.5f);\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"When to adjust:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Noisy environment:"})," Increase threshold (0.6-0.8)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Quiet environment:"})," Decrease threshold (0.3-0.5)"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"performance-tuning",children:"Performance Tuning"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Thread Count:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// Project Settings \u2192 STT \u2192 NumThreads\r\n// Set to CPU core count for best performance\r\nNumThreads = 4;  // For quad-core CPU\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Buffer Duration:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// Project Settings \u2192 Audio \u2192 Buffer Duration\r\nBufferDuration = 100ms;  // Lower = less latency, higher = better accuracy\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"language-models-llm",children:"Language Models (LLM)"}),"\n",(0,s.jsx)(n.h3,{id:"quick-setup-1",children:"Quick Setup"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'// 1. Add component\r\nUPROPERTY(VisibleAnywhere)\r\nUERP_LLMComponent* LLMComponent;\r\n\r\n// 2. Set system prompt\r\nLLMComponent->SetSystemPrompt(TEXT("You are a friendly merchant NPC."));\r\n\r\n// 3. Bind event\r\nLLMComponent->OnGenerationComplete.AddDynamic(\r\n    this, &AMyNPC::OnDialogueGenerated);\r\n\r\n// 4. Send message\r\nLLMComponent->SendMessage(TEXT("What are you selling?"));\r\n\r\n// 5. Handle response\r\nvoid AMyNPC::OnDialogueGenerated(const FElysLLMResult& Result)\r\n{\r\n    DisplayDialogue(Result.GeneratedText);\r\n}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"component-api-1",children:"Component API"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"SendMessage:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\r\nvoid SendMessage(const FString& Message);\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"SetSystemPrompt:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\r\nvoid SetSystemPrompt(const FString& Prompt);\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"ClearHistory:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\r\nvoid ClearHistory();\n'})}),"\n",(0,s.jsx)(n.h3,{id:"configuration-1",children:"Configuration"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Component Properties:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'UPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\r\nFString SystemPrompt = TEXT("You are a helpful assistant.");\r\n\r\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\r\nint32 MaxTokens = 256;\r\n\r\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\r\nfloat Temperature = 0.7f;  // 0.0-2.0\r\n\r\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\r\nint32 MaxHistoryMessages = 20;\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Project Settings:"})," Project Settings \u2192 Elys GenAI Framework \u2192 LLM"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Backend: LlamaCpp"}),"\n",(0,s.jsx)(n.li,{children:"Model Path: (empty = use bundled Phi-3)"}),"\n",(0,s.jsx)(n.li,{children:"ContextLength: 4096 tokens"}),"\n",(0,s.jsx)(n.li,{children:"NumThreads: 4"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"events-1",children:"Events"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"OnGenerationComplete:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"UPROPERTY(BlueprintAssignable)\r\nFElysLLMResultDelegate OnGenerationComplete;\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Result Structure:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\r\nstruct FElysLLMResult\r\n{\r\n    UPROPERTY(BlueprintReadOnly)\r\n    FString GeneratedText;\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    int32 TokenCount;\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    EElysLLMFinishReason FinishReason;  // Completed, Length, Stop\r\n};\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"OnTokenGenerated (Streaming):"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"UPROPERTY(BlueprintAssignable)\r\nFElysLLMTokenDelegate OnTokenGenerated;\n"})}),"\n",(0,s.jsx)(n.p,{children:"Use for typewriter effects:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"LLMComponent->OnTokenGenerated.AddDynamic(this, &AMyNPC::OnToken);\r\n\r\nvoid AMyNPC::OnToken(const FString& Token)\r\n{\r\n    DialogueText += Token;\r\n    UpdateDialogueUI(DialogueText);\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"bundled-model-phi-3-mini",children:"Bundled Model: Phi-3-mini"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Specs:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Size: ~2.7GB (Q4 quantized)"}),"\n",(0,s.jsx)(n.li,{children:"Context: 4096 tokens"}),"\n",(0,s.jsx)(n.li,{children:"License: MIT"}),"\n",(0,s.jsx)(n.li,{children:"Speed: ~20 tokens/sec (CPU)"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Use Cases:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"NPC dialogue"}),"\n",(0,s.jsx)(n.li,{children:"Quest generation"}),"\n",(0,s.jsx)(n.li,{children:"Item descriptions"}),"\n",(0,s.jsx)(n.li,{children:"Dynamic storytelling"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"temperature-guide",children:"Temperature Guide"}),"\n",(0,s.jsx)(n.p,{children:"Controls creativity/randomness:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// 0.0-0.3: Factual, deterministic (game mechanics, tutorials)\r\nLLMComponent->SetTemperature(0.3f);\r\n\r\n// 0.4-0.7: Balanced (NPC dialogue, descriptions)\r\nLLMComponent->SetTemperature(0.7f);\r\n\r\n// 0.8-1.5: Creative (storytelling, humor)\r\nLLMComponent->SetTemperature(1.2f);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"system-prompt-best-practices",children:"System Prompt Best Practices"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Clear Instructions:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'FString SystemPrompt = TEXT(\r\n    "You are a wise wizard NPC named Gandor. "\r\n    "Keep responses under 50 words. "\r\n    "Speak in archaic English. "\r\n    "Never break character."\r\n);\n'})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Few-Shot Examples:"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'FString SystemPrompt = TEXT(\r\n    "You are a merchant. Examples:\\n"\r\n    "Player: \'What do you sell?\'\\n"\r\n    "You: \'Potions, weapons, and armor!\'\\n"\r\n    "Player: \'How much for a sword?\'\\n"\r\n    "You: \'100 gold pieces.\'"\r\n);\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"combined-examples",children:"Combined Examples"}),"\n",(0,s.jsx)(n.h3,{id:"voice-to-dialogue-pipeline",children:"Voice-to-Dialogue Pipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'// 1. Capture audio \u2192 2. Transcribe \u2192 3. Generate response\r\n\r\nUCLASS()\r\nclass AMyNPC : public AActor\r\n{\r\n    GENERATED_BODY()\r\n\r\npublic:\r\n    UPROPERTY(VisibleAnywhere)\r\n    UERP_STTComponent* STTComponent;\r\n    \r\n    UPROPERTY(VisibleAnywhere)\r\n    UERP_LLMComponent* LLMComponent;\r\n\r\nprotected:\r\n    virtual void BeginPlay() override\r\n    {\r\n        Super::BeginPlay();\r\n        \r\n        // Setup STT\r\n        STTComponent->SetLanguageCode(TEXT("en"));\r\n        STTComponent->SetAutoStartListening(true);\r\n        STTComponent->OnTranscriptionComplete.AddDynamic(\r\n            this, &AMyNPC::OnPlayerSpoke);\r\n        \r\n        // Setup LLM\r\n        LLMComponent->SetSystemPrompt(TEXT("You are a friendly merchant."));\r\n        LLMComponent->OnGenerationComplete.AddDynamic(\r\n            this, &AMyNPC::OnDialogueGenerated);\r\n    }\r\n    \r\n    UFUNCTION()\r\n    void OnPlayerSpoke(const FElysSTTResult& Result)\r\n    {\r\n        // Send transcription to LLM\r\n        LLMComponent->SendMessage(Result.TranscribedText);\r\n    }\r\n    \r\n    UFUNCTION()\r\n    void OnDialogueGenerated(const FElysLLMResult& Result)\r\n    {\r\n        // Display NPC response\r\n        DisplayDialogue(Result.GeneratedText);\r\n    }\r\n};\n'})}),"\n",(0,s.jsx)(n.h3,{id:"multi-consumer-audio-routing",children:"Multi-Consumer Audio Routing"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:"// Route audio to both STT and voice chat\r\n\r\nUCLASS()\r\nclass AMyPlayerController : public APlayerController\r\n{\r\n    GENERATED_BODY()\r\n\r\npublic:\r\n    UPROPERTY(VisibleAnywhere)\r\n    UERP_STTComponent* STTComponent;\r\n    \r\n    UPROPERTY(VisibleAnywhere)\r\n    UVoiceChatComponent* VoiceChatComponent;\r\n\r\nprotected:\r\n    virtual void BeginPlay() override\r\n    {\r\n        Super::BeginPlay();\r\n        \r\n        // Both components automatically register as audio consumers\r\n        // Audio flows to both simultaneously\r\n        STTComponent->StartListening();\r\n        VoiceChatComponent->StartTransmitting();\r\n    }\r\n};\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"settings-reference",children:"Settings Reference"}),"\n",(0,s.jsx)(n.h3,{id:"audio-settings",children:"Audio Settings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Setting"}),(0,s.jsx)(n.th,{children:"Default"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Sample Rate"}),(0,s.jsx)(n.td,{children:"16000 Hz"}),(0,s.jsx)(n.td,{children:"Audio capture sample rate"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Channels"}),(0,s.jsx)(n.td,{children:"1 (Mono)"}),(0,s.jsx)(n.td,{children:"Audio channels"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Bit Depth"}),(0,s.jsx)(n.td,{children:"16"}),(0,s.jsx)(n.td,{children:"Audio bit depth"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Buffer Duration"}),(0,s.jsx)(n.td,{children:"100ms"}),(0,s.jsx)(n.td,{children:"Audio buffer size"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"stt-settings",children:"STT Settings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Setting"}),(0,s.jsx)(n.th,{children:"Default"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"STT Backend"}),(0,s.jsx)(n.td,{children:"Whisper"}),(0,s.jsx)(n.td,{children:"Backend implementation"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Model Path"}),(0,s.jsx)(n.td,{children:"(bundled)"}),(0,s.jsx)(n.td,{children:"Path to Whisper model"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Language"}),(0,s.jsx)(n.td,{children:"en"}),(0,s.jsx)(n.td,{children:"Target language code"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Enable VAD"}),(0,s.jsx)(n.td,{children:"true"}),(0,s.jsx)(n.td,{children:"Voice activity detection"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Num Threads"}),(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"Inference threads"})]})]})]}),"\n",(0,s.jsx)(n.h3,{id:"llm-settings",children:"LLM Settings"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Setting"}),(0,s.jsx)(n.th,{children:"Default"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"LLM Backend"}),(0,s.jsx)(n.td,{children:"LlamaCpp"}),(0,s.jsx)(n.td,{children:"Backend implementation"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Model Path"}),(0,s.jsx)(n.td,{children:"(bundled)"}),(0,s.jsx)(n.td,{children:"Path to Phi-3 model"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Context Length"}),(0,s.jsx)(n.td,{children:"4096"}),(0,s.jsx)(n.td,{children:"Maximum context tokens"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Temperature"}),(0,s.jsx)(n.td,{children:"0.7"}),(0,s.jsx)(n.td,{children:"Sampling temperature"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Max Tokens"}),(0,s.jsx)(n.td,{children:"512"}),(0,s.jsx)(n.td,{children:"Maximum generation length"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"Num Threads"}),(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"Inference threads"})]})]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ElysGenAIPlugin/Examples",children:"Examples"})})," - Practical implementation recipes"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ElysGenAIPlugin/API-Reference",children:"API Reference"})})," - Complete class documentation"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ElysGenAIPlugin/Troubleshooting",children:"Troubleshooting"})})," - Common issues and solutions"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453(e,n,r){r.d(n,{R:()=>l,x:()=>d});var t=r(6540);const s={},i=t.createContext(s);function l(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);