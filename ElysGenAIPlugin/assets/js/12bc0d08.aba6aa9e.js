"use strict";(globalThis.webpackChunkelysgenai_docs=globalThis.webpackChunkelysgenai_docs||[]).push([[55],{294(e,n,r){r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"LLMGuide","title":"Language Model Guide","description":"Using Large Language Models for NPC dialogue and reasoning in ElysGenAI.","source":"@site/../Documentation/LLMGuide.md","sourceDirName":".","slug":"/LLMGuide","permalink":"/ElysGenAIPlugin/LLMGuide","draft":false,"unlisted":false,"editUrl":"https://github.com/RogueParadigm/ElysGenAIPlugin/tree/main/Documentation/../Documentation/LLMGuide.md","tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"id":"LLMGuide","title":"Language Model Guide","sidebar_position":9},"sidebar":"docsSidebar","previous":{"title":"Speech-to-Text Guide","permalink":"/ElysGenAIPlugin/STTGuide"},"next":{"title":"Examples","permalink":"/ElysGenAIPlugin/Examples"}}');var i=r(4848),l=r(8453);const t={id:"LLMGuide",title:"Language Model Guide",sidebar_position:9},o="Language Model Guide",a={},d=[{value:"Quick Setup",id:"quick-setup",level:2},{value:"Component API",id:"component-api",level:2},{value:"SendMessage",id:"sendmessage",level:3},{value:"SetSystemPrompt",id:"setsystemprompt",level:3},{value:"ClearHistory",id:"clearhistory",level:3},{value:"Configuration",id:"configuration",level:2},{value:"Component Properties",id:"component-properties",level:3},{value:"Project Settings",id:"project-settings",level:3},{value:"Events",id:"events",level:2},{value:"OnGenerationComplete",id:"ongenerationcomplete",level:3},{value:"OnTokenGenerated (Streaming)",id:"ontokengenerated-streaming",level:3},{value:"Models",id:"models",level:2},{value:"Bundled Model: Phi-3-mini",id:"bundled-model-phi-3-mini",level:3},{value:"Supported Models",id:"supported-models",level:3},{value:"Custom Models",id:"custom-models",level:3},{value:"Temperature &amp; Sampling",id:"temperature--sampling",level:2},{value:"Temperature",id:"temperature",level:3},{value:"Examples",id:"examples",level:2},{value:"NPC Merchant",id:"npc-merchant",level:3},{value:"Quest Generator",id:"quest-generator",level:3},{value:"Dynamic Item Descriptions",id:"dynamic-item-descriptions",level:3},{value:"Streaming Responses",id:"streaming-responses",level:2},{value:"Token-by-Token",id:"token-by-token",level:3},{value:"Performance",id:"performance",level:2},{value:"Generation Speed",id:"generation-speed",level:3},{value:"Memory Usage",id:"memory-usage",level:3},{value:"Optimization",id:"optimization",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Slow Generation",id:"slow-generation",level:3},{value:"Out of Memory",id:"out-of-memory",level:3},{value:"Inconsistent Responses",id:"inconsistent-responses",level:3},{value:"Model Not Loading",id:"model-not-loading",level:3},{value:"Advanced",id:"advanced",level:2},{value:"Custom Prompting",id:"custom-prompting",level:3},{value:"Few-Shot Learning",id:"few-shot-learning",level:3},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,l.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"language-model-guide",children:"Language Model Guide"})}),"\n",(0,i.jsx)(n.p,{children:"Using Large Language Models for NPC dialogue and reasoning in ElysGenAI."}),"\n",(0,i.jsx)(n.h2,{id:"quick-setup",children:"Quick Setup"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'// 1. Add component\r\nUPROPERTY(VisibleAnywhere)\r\nUERP_LLMComponent* LLMComponent;\r\n\r\n// 2. Set system prompt\r\nLLMComponent->SetSystemPrompt(TEXT("You are a friendly merchant NPC."));\r\n\r\n// 3. Bind event\r\nLLMComponent->OnGenerationComplete.AddDynamic(\r\n    this, &AMyNPC::OnDialogueGenerated);\r\n\r\n// 4. Send message\r\nLLMComponent->SendMessage(TEXT("What are you selling?"));\r\n\r\n// 5. Handle response\r\nvoid AMyNPC::OnDialogueGenerated(const FElysLLMResult& Result)\r\n{\r\n    DisplayDialogue(Result.GeneratedText);\r\n}\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"component-api",children:"Component API"}),"\n",(0,i.jsx)(n.h3,{id:"sendmessage",children:"SendMessage"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\r\nvoid SendMessage(const FString& Message);\n'})}),"\n",(0,i.jsx)(n.p,{children:"Send a message and generate response."}),"\n",(0,i.jsx)(n.h3,{id:"setsystemprompt",children:"SetSystemPrompt"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\r\nvoid SetSystemPrompt(const FString& Prompt);\n'})}),"\n",(0,i.jsx)(n.p,{children:"Set AI personality/instructions."}),"\n",(0,i.jsx)(n.h3,{id:"clearhistory",children:"ClearHistory"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UFUNCTION(BlueprintCallable, Category="ElysGenAI|LLM")\r\nvoid ClearHistory();\n'})}),"\n",(0,i.jsx)(n.p,{children:"Clear conversation history."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"configuration",children:"Configuration"}),"\n",(0,i.jsx)(n.h3,{id:"component-properties",children:"Component Properties"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\r\nFString SystemPrompt = TEXT("You are a helpful assistant.");\r\n\r\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\r\nint32 MaxTokens = 256;  // Max response length\r\n\r\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\r\nfloat Temperature = 0.7f;  // Creativity (0.0-2.0)\r\n\r\nUPROPERTY(EditAnywhere, Category="ElysGenAI|LLM")\r\nint32 MaxHistoryMessages = 20;  // Context window\n'})}),"\n",(0,i.jsx)(n.h3,{id:"project-settings",children:"Project Settings"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// Backend\r\nEElysLLMBackendType LLMBackend = EElysLLMBackendType::LlamaCpp;\r\n\r\n// Model path (empty = use bundled Phi-3)\r\nFString LLMModelPath;\r\n\r\n// Performance\r\nint32 ContextLength = 4096;  // Token context window\r\nint32 NumThreads = 4;\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"events",children:"Events"}),"\n",(0,i.jsx)(n.h3,{id:"ongenerationcomplete",children:"OnGenerationComplete"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"UPROPERTY(BlueprintAssignable)\r\nFElysLLMResultDelegate OnGenerationComplete;\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Result Structure:"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"USTRUCT(BlueprintType)\r\nstruct FElysLLMResult\r\n{\r\n    UPROPERTY(BlueprintReadOnly)\r\n    FString GeneratedText;\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    int32 TokenCount;\r\n    \r\n    UPROPERTY(BlueprintReadOnly)\r\n    EElysLLMFinishReason FinishReason;  // Completed, Length, Stop\r\n};\n"})}),"\n",(0,i.jsx)(n.h3,{id:"ontokengenerated-streaming",children:"OnTokenGenerated (Streaming)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"UPROPERTY(BlueprintAssignable)\r\nFElysLLMTokenDelegate OnTokenGenerated;\n"})}),"\n",(0,i.jsx)(n.p,{children:"Fires for each token during generation (typewriter effect)."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"models",children:"Models"}),"\n",(0,i.jsx)(n.h3,{id:"bundled-model-phi-3-mini",children:"Bundled Model: Phi-3-mini"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Specs:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Size: ~2.7GB (Q4 quantized)"}),"\n",(0,i.jsx)(n.li,{children:"Context: 4096 tokens"}),"\n",(0,i.jsx)(n.li,{children:"License: MIT"}),"\n",(0,i.jsx)(n.li,{children:"Speed: ~20 tokens/sec (CPU)"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Use Cases:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"NPC dialogue"}),"\n",(0,i.jsx)(n.li,{children:"Quest generation"}),"\n",(0,i.jsx)(n.li,{children:"Item descriptions"}),"\n",(0,i.jsx)(n.li,{children:"Dynamic storytelling"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"supported-models",children:"Supported Models"}),"\n",(0,i.jsx)(n.p,{children:"All GGUF format models from:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Phi-3"})," (Microsoft, MIT) - Bundled"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gemma 2"})," (Google, Apache 2.0)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mistral"})," (Mistral AI, Apache 2.0)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Llama 3"})," (Meta, Llama Community License)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TinyLlama"})," (Small, Apache 2.0)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"custom-models",children:"Custom Models"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'// Set in Project Settings \u2192 LLM \u2192 Model Path\r\nLLMModelPath = "C:/Models/mistral-7b-instruct-q4.gguf";\n'})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Download from:"})," ",(0,i.jsx)(n.a,{href:"https://huggingface.co/models?library=gguf",children:"https://huggingface.co/models?library=gguf"})]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"temperature--sampling",children:"Temperature & Sampling"}),"\n",(0,i.jsx)(n.h3,{id:"temperature",children:"Temperature"}),"\n",(0,i.jsx)(n.p,{children:"Controls randomness:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// Conservative (factual, consistent)\r\nLLMComponent->SetTemperature(0.3f);\r\n\r\n// Balanced (default)\r\nLLMComponent->SetTemperature(0.7f);\r\n\r\n// Creative (varied, unpredictable)\r\nLLMComponent->SetTemperature(1.5f);\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Guidelines:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"0.0-0.3:"})," Quest dialogs, tutorials"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"0.5-0.8:"})," NPC conversations"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"1.0-2.0:"})," Creative writing, variety"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,i.jsx)(n.h3,{id:"npc-merchant",children:"NPC Merchant"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'UCLASS()\r\nclass AMerchantNPC : public ACharacter\r\n{\r\n    UPROPERTY(VisibleAnywhere)\r\n    UERP_LLMComponent* LLMComponent;\r\n    \r\n    void BeginPlay() override\r\n    {\r\n        Super::BeginPlay();\r\n        \r\n        LLMComponent->SetSystemPrompt(\r\n            TEXT("You are Gareth, a friendly blacksmith. "\r\n                 "You sell weapons and armor. "\r\n                 "You\'re jovial and love to chat about crafting."));\r\n        \r\n        LLMComponent->SetTemperature(0.8f);\r\n        LLMComponent->SetMaxTokens(100);\r\n    }\r\n    \r\n    UFUNCTION(BlueprintCallable)\r\n    void TalkTo(const FString& PlayerMessage)\r\n    {\r\n        LLMComponent->SendMessage(PlayerMessage);\r\n    }\r\n    \r\n    UFUNCTION()\r\n    void OnDialogueGenerated(const FElysLLMResult& Result)\r\n    {\r\n        DisplayDialogueBubble(Result.GeneratedText);\r\n        PlayVoiceSound();\r\n    }\r\n};\n'})}),"\n",(0,i.jsx)(n.h3,{id:"quest-generator",children:"Quest Generator"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'FString GenerateQuest(const FString& QuestType, const FString& Location)\r\n{\r\n    FString Prompt = FString::Printf(\r\n        TEXT("Generate a %s quest that takes place in %s. "\r\n             "Include: objective, reward, and a twist. "\r\n             "Keep it under 100 words."),\r\n        *QuestType, *Location);\r\n    \r\n    LLMComponent->SendMessageSync(Prompt);  // Blocking call\r\n    return LLMComponent->GetLastResponse();\r\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"dynamic-item-descriptions",children:"Dynamic Item Descriptions"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'void GenerateItemLore(UInventoryItemERP* Item)\r\n{\r\n    FString Prompt = FString::Printf(\r\n        TEXT("Write a brief fantasy lore description for: %s. "\r\n             "Make it mysterious and intriguing. Max 50 words."),\r\n        *Item->ItemName);\r\n    \r\n    LLMComponent->OnGenerationComplete.AddDynamic(\r\n        this, &UInventorySystem::OnLoreGenerated);\r\n    \r\n    LLMComponent->SendMessage(Prompt);\r\n}\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"streaming-responses",children:"Streaming Responses"}),"\n",(0,i.jsx)(n.h3,{id:"token-by-token",children:"Token-by-Token"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"void AMerchantNPC::BeginPlay()\r\n{\r\n    Super::BeginPlay();\r\n    \r\n    // Enable streaming\r\n    LLMComponent->SetStreamingEnabled(true);\r\n    \r\n    // Bind token event\r\n    LLMComponent->OnTokenGenerated.AddDynamic(\r\n        this, &AMerchantNPC::OnTokenReceived);\r\n}\r\n\r\nvoid AMerchantNPC::OnTokenReceived(const FString& Token)\r\n{\r\n    // Append to dialogue (typewriter effect)\r\n    CurrentDialogue += Token;\r\n    UpdateDialogueWidget(CurrentDialogue);\r\n}\r\n\r\nvoid AMerchantNPC::OnDialogueComplete(const FElysLLMResult& Result)\r\n{\r\n    // Final cleanup\r\n    FinalizeDialogue(Result.GeneratedText);\r\n}\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"performance",children:"Performance"}),"\n",(0,i.jsx)(n.h3,{id:"generation-speed",children:"Generation Speed"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Phi-3-mini (Q4):"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"CPU (8-core): ~15-25 tokens/sec"}),"\n",(0,i.jsx)(n.li,{children:"CPU (16-core): ~30-50 tokens/sec"}),"\n",(0,i.jsx)(n.li,{children:"GPU (future): ~100+ tokens/sec"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Latency:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"First token: ~200-500ms"}),"\n",(0,i.jsx)(n.li,{children:"Subsequent tokens: ~40-70ms each"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"memory-usage",children:"Memory Usage"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Phi-3-mini Q4:"})," ~2.7GB RAM"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mistral 7B Q4:"})," ~4GB RAM"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Llama 3 8B Q4:"})," ~4.5GB RAM"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"optimization",children:"Optimization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:"// Reduce context window for faster inference\r\nSettings->ContextLength = 2048;  // Default: 4096\r\n\r\n// Use fewer threads if CPU-bound\r\nSettings->NumThreads = 2;\r\n\r\n// Shorter responses\r\nLLMComponent->SetMaxTokens(50);  // Default: 256\n"})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"slow-generation",children:"Slow Generation"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Reduce ",(0,i.jsx)(n.code,{children:"MaxTokens"})]}),"\n",(0,i.jsx)(n.li,{children:"Use smaller model (Phi-3 \u2192 TinyLlama)"}),"\n",(0,i.jsxs)(n.li,{children:["Reduce ",(0,i.jsx)(n.code,{children:"NumThreads"})]}),"\n",(0,i.jsx)(n.li,{children:"Close other CPU-intensive apps"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"out-of-memory",children:"Out of Memory"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Use smaller model"}),"\n",(0,i.jsxs)(n.li,{children:["Reduce ",(0,i.jsx)(n.code,{children:"ContextLength"})]}),"\n",(0,i.jsx)(n.li,{children:"Clear history more frequently"}),"\n",(0,i.jsx)(n.li,{children:"Close other memory-intensive apps"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"inconsistent-responses",children:"Inconsistent Responses"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Lower ",(0,i.jsx)(n.code,{children:"Temperature"})," (0.7 \u2192 0.3)"]}),"\n",(0,i.jsx)(n.li,{children:"Use more specific system prompts"}),"\n",(0,i.jsx)(n.li,{children:"Provide examples in prompt"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"model-not-loading",children:"Model Not Loading"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Check model path in settings"}),"\n",(0,i.jsx)(n.li,{children:"Verify GGUF format"}),"\n",(0,i.jsx)(n.li,{children:"Check file permissions"}),"\n",(0,i.jsx)(n.li,{children:"Check Output Log for errors"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"advanced",children:"Advanced"}),"\n",(0,i.jsx)(n.h3,{id:"custom-prompting",children:"Custom Prompting"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'FString BuildPrompt()\r\n{\r\n    return FString::Printf(\r\n        TEXT("System: %s\\n"\r\n             "Context: %s\\n"\r\n             "Player: %s\\n"\r\n             "NPC:"),\r\n        *SystemPrompt,\r\n        *GetGameContext(),\r\n        *PlayerMessage);\r\n}\n'})}),"\n",(0,i.jsx)(n.h3,{id:"few-shot-learning",children:"Few-Shot Learning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-cpp",children:'void SetupNPC()\r\n{\r\n    LLMComponent->SetSystemPrompt(\r\n        TEXT("You are a guard. Examples:\\n"\r\n             "Player: Can I enter?\\n"\r\n             "Guard: Not without a pass!\\n\\n"\r\n             "Player: Here\'s my pass.\\n"\r\n             "Guard: Alright, go ahead."));\r\n}\n'})}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/ElysGenAIPlugin/Examples",children:"Examples"})})," - More LLM use cases"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/ElysGenAIPlugin/AdvancedCustomization",children:"Advanced Customization"})})," - Custom backends"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/ElysGenAIPlugin/API-Reference",children:"API Reference"})})," - Complete API docs"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453(e,n,r){r.d(n,{R:()=>t,x:()=>o});var s=r(6540);const i={},l=s.createContext(i);function t(e){const n=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(l.Provider,{value:n},e.children)}}}]);